# 预训练模型

## 前言

要提到预训练模型就要提到迁移学习，迁移学习指的是在一个**源任务（source task）**上训练好的模型，其学到的知识能**迁移**到一个**目标任务（target task）**上，从而提升目标任务的性能，尤其是在目标任务数据量较小的情况下。而**预训练模型是迁移学习的典型手段和载体**

## 使用预训练模型的步骤

1. 预训练
2. 在具体的下游任务中调整
3. 推理

## 预训练

在一个**大规模数据集**和**通用任务**上训练模型，目标是**学习通用的表示能力**，之后可以用于其他下游任务。例如在自然语言处理中，我们会预训练transformer及他的改进模型，通过设置巧妙的预训练任务，期望他能学习到通用的表达能力，泛化到下游任务，如文本分类，文本总结，文本翻译等。在对比学习中，我们为模型设置代理任务，如最常见的个体判别，同样希望他能学习到如何能充分表示图片的信息，从而作为特征提取器作用于下游任务。这一过程就是预训练。他有几个特点：

1. 通常训练代价很高，需要大量数据和算力
2. 并不针对某个特定任务，而是学习通用知识，如语言的理解，图像的特征

## 在具体的下游任务中调整

在下游任务中使用预训练模型的方式有好几种，因为我们预训练的模型只能提供通用的知识表示，**无法直接作用**于特定的下游任务了。

### 1. 特征提取（Feature Extraction）

冻结预训练模型所有参数，只在其输出基础上**加上新的任务层（如分类器）进行训练，**在评估预训练模型在下游任务中的效果，有时就采用这种方式，但是在要求高效果和比赛场景下，这样做的效果往往不够好。

因为在预训练时我们的任务就是，得到更好的通用的表示能力以作用于下游任务的，所以我们认为他是可以直接用的，只需要再接上具体的任务层，把这个预训练的模型当作特征提取器就好了。此时我们直接冻结预训练模型的参数，防止后续反向传播更新他，也就是说，在下游任务进行训练时，我们**只优化任务层**。

- **适用场景：**

  - 下游数据量很小
  - 计算资源有限
  - 不希望破坏预训练知识
- **优点：**

  - 快速、稳定
  - 训练代价低
- **缺点：**

  - 不如微调灵活，适应性差

### 2. 微调(Partial Fine-Tuning)

不再把预训练模型冻住，而是继续训练它，以适应新任务。我们选择继续训练部分或全部预训练模型参数来适应新任务。根据训练的参数不同，这种方式分为几种

| 微调类型                          | 做法                     | 场景               |
| --------------------------------- | ------------------------ | ------------------ |
| 全模型微调                        | 所有层都参与训练         | 大数据集，强适应性 |
| 分层微调                          | 只训练上几层或中间几层   | 中小数据，防过拟合 |
| 逐步解冻（Layer-wise Unfreezing） | 先冻结，后解冻一层层训练 | 预防训练震荡       |

使用场景：

| 使用场景           | 示例                           | 说明                             |
| ------------------ | ------------------------------ | -------------------------------- |
| 数据充足的任务     | 新闻分类、图像识别、机器翻译等 | 微调效果更好，能充分发挥模型潜力 |
| 与预训练任务相近   | BERT → 文本分类、问答任务     | 迁移效果更好，所需训练较少       |
| 高准确率要求的应用 | 医疗影像、法律文书分类等       | 不容忍“只用特征提取”的简单方法 |
| 定制化服务场景     | 企业私有客服系统、专属风格生成 | 微调可以让模型“学懂企业语言”   |
| 多语言、多领域任务 | 法语情感分析、金融文本问答     | 适应不同领域术语和结构需要微调   |

优点：

| 优点                       | 解释                                                                       |
| -------------------------- | -------------------------------------------------------------------------- |
| **性能强大**         | 微调能利用预训练表示能力，同时学习目标任务特性，通常比特征提取方法表现更优 |
| **适应性强**         | 可用于任意任务类型（分类、生成、翻译、问答...），适用性广泛                |
| **预训练“再利用”** | 不用从头训练，节省时间和算力                                               |
| **灵活性高**         | 可选择全调、半调、冻结部分，控制计算成本与性能平衡                         |
| **更少手工设计**     | 不需要设计特征，模型会自动“迁移学习”关键特征                             |

缺点：

| 缺点                            | 解释                                                                     |
| ------------------------------- | ------------------------------------------------------------------------ |
| **对资源要求高**          | 尤其是全模型微调，大模型（如 GPT、T5）需要大量显存与计算资源             |
| **容易过拟合**            | 特别是在下游数据很少时，模型可能记住训练数据而不是泛化规律               |
| **参数冗余**              | 每个任务都要拷贝一套完整模型（如 1 个 BERT = 110M 参数），难以多任务共享 |
| **不易快速迁移/切换任务** | 不像 Adapter/LoRA 那样“插件式”切换任务，需要加载整套模型               |
| **可能破坏预训练知识**    | 若学习率不合理，微调可能破坏预训练时学到的有用结构（尤其是低层）         |

---

### 3. 插入模块微调（Parameter-efficient Fine-tuning）

在不调整或少调整原模型参数的前提下，通过**插入少量新参数**来完成微调

| 方法                        | 简述                                     | 适用场景                |
| --------------------------- | ---------------------------------------- | ----------------------- |
| Adapter Tuning              | 每层加小网络（Adapter），只调Adapter参数 | 多任务、参数复用        |
| LoRA（Low-Rank Adaptation） | 将大矩阵的更新部分限制为低秩形式         | 大模型微调（如LLM）     |
| Prompt Tuning               | 给输入加“可训练的提示向量”             | NLP大模型，少量任务数据 |
| Prefix Tuning               | 训练输入前缀的表示，冻结主模型           | 类似Prompt，但更灵活    |

#### Adapter Tuning

添加小网络的位置有两个

1. 在Attention后，add+norm之前
2. 在FFN之后，add+norm之前

Adaper Tunning会先降维后升维，他会保证维度前后不变

#### LoRA

$W = W_0 + \Delta W = W_0 + BA$

不对模型原参数进行更改，插入低秩矩阵进行微调，常用于q,v权重矩阵，将将两个较小矩阵B和A加入进去作为可学习参数。

##### QLoRA

对模型进行4bit或8bit量化后做LoRA就是QLoRA

#### Prompt Tuning

相当于添加一个embedding到原输入的embedding的前面，其值初始化为随机值或其他的，后续使用backward进行更新，其实相当于模型根据这个embedding的训练学习到了一套很适合这个任务的提示词。

$X' = [p_1, p_2, \dots, p_m, x_1, x_2, \dots, x_n]$

前面的$p_i$就是Prompt

#### Prefix Tuning

**做法** ：不给输入序列真的加“前缀 token”，而是 **在每一层的注意力里直接拼接一段可训练的 Key/Value（KV）向量** ，让真实输入的 Query 可以 **先“看到”这段学到的上下文** ，再去看真实输入。


$$
K^{(l)}_{\text{cat}}=[K^{(l)}_{\text{pref}};\,K_x],\quad
V^{(l)}_{\text{cat}}=[V^{(l)}_{\text{pref}};\,V_x]
$$

在K,V向量后接一段，这是已经经过权重矩阵的

$\text{Attn}(Q, K_x, V_x)\ \Rightarrow\ \text{Attn}\!\left(Q,\ [K_{\text{pref}};K_x],\ [V_{\text{pref}};V_x]\right)$

### 4. 全参数微调 (Full Fine-Tuning)

- **方法**：更新模型里所有参数。
- **优点**：效果最好，能充分适配新任务。
- **缺点**：显存、存储开销巨大（数亿/千亿参数要全部保存），多任务适配很不现实。
- **适用场景**：模型规模中小（几十亿以下）、计算资源充足时。



